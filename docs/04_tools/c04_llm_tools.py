import dashscope
import re
import json
import os
import requests
from typing import List, Dict, Optional, Callable
from dashscope import Generation

# ====================== å…¨å±€é…ç½® ======================
# 1. LLMé…ç½®ï¼ˆæ›¿æ¢ä¸ºä½ çš„API Keyï¼‰
dashscope.api_key = "YOUR_API_KEY"
LLM_MODEL = "qwen-turbo"
LLM_TEMPERATURE = 0.2

# 2. é•¿æœŸè®°å¿†é…ç½®
LONG_TERM_MEMORY_PATH = "llm_agent_long_memory.json"
MAX_MEMORY_LENGTH = 20  # æœ€å¤§è®°å¿†æ¡æ•°

# ====================== é•¿æœŸè®°å¿†å·¥å…·å‡½æ•° ======================
def load_long_term_memory() -> List[Dict[str, str]]:
    """åŠ è½½é•¿æœŸè®°å¿†ï¼ˆä¿ç•™ç¬¬3ç« é€»è¾‘ï¼Œè¡¥å……æ ¼å¼æ ¡éªŒï¼‰"""
    if os.path.exists(LONG_TERM_MEMORY_PATH):
        try:
            with open(LONG_TERM_MEMORY_PATH, "r", encoding="utf-8") as f:
                memory = json.load(f)
                if isinstance(memory, list):
                    print(f"âœ… åŠ è½½é•¿æœŸè®°å¿†æˆåŠŸï¼Œå…±{len(memory)}æ¡è®°å½•")
                    return memory
                else:
                    print("âš ï¸ è®°å¿†æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œåˆå§‹åŒ–ç©ºè®°å¿†")
                    return []
        except Exception as e:
            print(f"âš ï¸ åŠ è½½è®°å¿†å¼‚å¸¸ï¼š{str(e)}ï¼Œåˆå§‹åŒ–ç©ºè®°å¿†")
            return []
    else:
        with open(LONG_TERM_MEMORY_PATH, "w", encoding="utf-8") as f:
            json.dump([], f, ensure_ascii=False, indent=2)
        print("âœ… å·²åˆ›å»ºæ–°çš„é•¿æœŸè®°å¿†æ–‡ä»¶")
        return []

def save_long_term_memory(memory: List[Dict[str, str]]) -> None:
    """ä¿å­˜é•¿æœŸè®°å¿†ï¼ˆé™åˆ¶é•¿åº¦ï¼Œä¿ç•™ç¬¬3ç« é€»è¾‘ï¼‰"""
    try:
        trimmed_memory = memory[-MAX_MEMORY_LENGTH:]
        with open(LONG_TERM_MEMORY_PATH, "w", encoding="utf-8") as f:
            json.dump(trimmed_memory, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜é•¿æœŸè®°å¿†å¤±è´¥ï¼š{str(e)}")

# ====================== å·¥å…·å‡½æ•°åº“ ======================
def get_weather(city: str) -> str:
    """å¤©æ°”æŸ¥è¯¢å·¥å…·ï¼ˆå®Œæ•´å¼‚å¸¸å¤„ç†ç‰ˆï¼‰"""
    if not city or city.strip() == "":
        return "âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„åŸå¸‚åï¼ˆå¦‚åŒ—äº¬ã€ä¸Šæµ·ï¼‰"
    
    try:
        # url = f"https://wttr.in/{city.strip()}?format=3" # åŸå§‹URLï¼Œå»¶è¿Ÿæ¯”è¾ƒå¤§ï¼Œå› æ­¤ä½¿ç”¨uapis.cnçš„API
        import urllib.parse
        encoded_city = urllib.parse.quote(city.strip())
        url = f'https://uapis.cn/api/v1/misc/weather?city={encoded_city}'
        headers = {"User-Agent": "Mozilla/5.0"}
        # ç§»é™¤verify=Falseä»¥é¿å…SSLè­¦å‘Šï¼Œæˆ–ä½¿ç”¨requests.packages.urllib3.disable_warnings()
        import requests.packages.urllib3
        requests.packages.urllib3.disable_warnings()
        response = requests.get(url, headers=headers, timeout=10, verify=False)
        response.raise_for_status()
        # ç›´æ¥ä½¿ç”¨response.textï¼Œrequestsä¼šè‡ªåŠ¨å¤„ç†ç¼–ç 
        weather_info = response.text
        return f"âœ… {weather_info}"
    except requests.exceptions.Timeout:
        return "âŒ å¤©æ°”APIè¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
    except requests.exceptions.HTTPError:
        return "âŒ åŸå¸‚ä¸å­˜åœ¨æˆ–APIè¿”å›é”™è¯¯"
    except requests.exceptions.RequestException as e:
        return f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼š{str(e)}"
    except Exception as e:
        return f"âŒ å¤©æ°”æŸ¥è¯¢å¼‚å¸¸ï¼š{str(e)}"

def calculate_tool(expression: str) -> str:
    """è®¡ç®—å™¨å·¥å…·ï¼ˆå®‰å…¨ä¼˜åŒ–ç‰ˆï¼‰"""
    allowed_chars = set("0123456789+-*/(). ")
    if not all(char in allowed_chars for char in expression):
        return "âŒ è®¡ç®—è¡¨è¾¾å¼éæ³•ï¼Œä»…æ”¯æŒæ•°å­—å’Œ+-*/()è¿ç®—"
    
    try:
        result = eval(expression)
        return f"âœ… è®¡ç®—ç»“æœï¼š{expression} = {result}"
    except ZeroDivisionError:
        return "âŒ è®¡ç®—é”™è¯¯ï¼šé™¤æ•°ä¸èƒ½ä¸º0"
    except SyntaxError:
        return "âŒ è®¡ç®—é”™è¯¯ï¼šè¡¨è¾¾å¼è¯­æ³•é”™è¯¯ï¼ˆå¦‚ç¼ºå°‘æ‹¬å·ï¼‰"
    except Exception as e:
        return f"âŒ è®¡ç®—å¤±è´¥ï¼š{str(e)}"

# ====================== å¤šå·¥å…·æ™ºèƒ½ä½“ä¸»ç±» ======================
class MultiToolLLMAgent:
    def __init__(self):
        self.memory = load_long_term_memory()  # åŠ è½½é•¿æœŸè®°å¿†

    def perceive(self) -> str:
        """æ„ŸçŸ¥æ¨¡å—ï¼šè·å–ç”¨æˆ·è¾“å…¥ï¼ˆè¿‡æ»¤ç©ºå€¼ï¼‰"""
        user_input = input("ä½ ï¼š").strip()
        if not user_input:
            print("æ™ºèƒ½ä½“ï¼šè¯·è¾“å…¥æœ‰æ•ˆå†…å®¹ï½")
            return self.perceive()
        return user_input

    def decide(self, user_input: str) -> str:
        """å†³ç­–æ¨¡å—ï¼šLLMæ¨ç†ï¼ˆå¤šå·¥å…·è°ƒç”¨è§„åˆ™ï¼‰"""
        # æ¸…ç©ºè®°å¿†æŒ‡ä»¤
        if "æ¸…ç©ºè®°å¿†" in user_input:
            self.memory = []
            save_long_term_memory(self.memory)
            return "âœ… å·²æ¸…ç©ºæ‰€æœ‰é•¿æœŸè®°å¿†ï¼"

        # ç³»ç»Ÿæç¤ºè¯ï¼ˆå¤šå·¥å…·è§„åˆ™ï¼‰
        system_prompt = {
            "role": "system",
            "content": """
ä½ æ˜¯å…·å¤‡é•¿æœŸè®°å¿†å’Œå¤šå·¥å…·è°ƒç”¨èƒ½åŠ›çš„æ™ºèƒ½ä½“ï¼Œä¸¥æ ¼éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
1. å¯ç”¨å·¥å…·åˆ—è¡¨ï¼š
   - calculate(æ•°å­¦è¡¨è¾¾å¼)ï¼šæ‰§è¡Œæ•°å­¦è®¡ç®—ï¼Œå‚æ•°ä¸ºåˆæ³•æ•°å­¦è¡¨è¾¾å¼ï¼›
   - get_weather(åŸå¸‚å)ï¼šæŸ¥è¯¢åŸå¸‚å¤©æ°”ï¼Œå‚æ•°ä¸ºä¸­æ–‡åŸå¸‚åã€‚
2. å·¥å…·è°ƒç”¨æ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼Œæ— é¢å¤–å†…å®¹ï¼‰ï¼š
   æ­£ç¡®ï¼šTOOL: calculate(100+200)ã€TOOL: get_weather(å¹¿å·)
3. å›å¤è§„åˆ™ï¼š
   - ä»…è®¡ç®—/æŸ¥å¤©æ°”éœ€æ±‚è°ƒç”¨å¯¹åº”å·¥å…·ï¼Œå…¶ä»–éœ€æ±‚ç›´æ¥è‡ªç„¶è¯­è¨€å›å¤ï¼›
   - å›å¤ç®€æ´ï¼Œéå·¥å…·è°ƒç”¨å†…å®¹ä¸è¶…è¿‡100å­—ã€‚
            """
        }

        # æ„é€ LLMè¾“å…¥
        messages = [system_prompt] + self.memory
        messages.append({"role": "user", "content": user_input})

        # è°ƒç”¨LLM API
        try:
            response = Generation.call(
                model=LLM_MODEL,
                messages=messages,
                temperature=LLM_TEMPERATURE,
                top_p=0.5
            )
            return response.output.text
        except Exception as e:
            return f"LLMè°ƒç”¨å¤±è´¥ï¼š{str(e)}"

    def parse_tool_call(self, llm_output: str) -> Optional[Dict[str, str]]:
        """é€šç”¨å·¥å…·æŒ‡ä»¤è§£æï¼ˆæ”¯æŒå¤šå·¥å…·ï¼‰"""
        pattern = r"^TOOL:\s*(\w+)\((.*?)\)$"
        match = re.match(pattern, llm_output.strip(), re.IGNORECASE)
        if not match:
            return None
        return {
            "tool": match.group(1).strip().lower(),
            "params": match.group(2).strip()
        }

    def execute_tool(self, tool_info: Dict[str, str]) -> str:
        """å·¥å…·æ‰§è¡Œï¼ˆæ˜ å°„è¡¨è°ƒç”¨ï¼‰"""
        tool_mapping = {
            "calculate": calculate_tool,
            "get_weather": get_weather
        }
        tool_name = tool_info["tool"]
        tool_params = tool_info["params"]
        
        if tool_name in tool_mapping:
            try:
                return tool_mapping[tool_name](tool_params)
            except Exception as e:
                return f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥ï¼š{str(e)}"
        else:
            return f"âŒ æœªçŸ¥å·¥å…·ï¼š{tool_name}ï¼Œä»…æ”¯æŒcalculate/get_weather"

    def act(self, llm_reply: str, user_input: str) -> str:
        """åŠ¨ä½œæ¨¡å—ï¼šæ‰§è¡Œå·¥å…·/è¾“å‡ºå›å¤"""
        tool_info = self.parse_tool_call(llm_reply)
        if tool_info:
            tool_result = self.execute_tool(tool_info)
            print(f"æ™ºèƒ½ä½“ï¼ˆ{tool_info['tool']}å·¥å…·ï¼‰ï¼š{tool_result}")
            final_reply = tool_result
        else:
            final_reply = llm_reply.strip()
            print(f"æ™ºèƒ½ä½“ï¼š{final_reply}")

        # æ›´æ–°å¹¶ä¿å­˜è®°å¿†
        self.memory.append({"role": "user", "content": user_input})
        self.memory.append({"role": "assistant", "content": final_reply})
        save_long_term_memory(self.memory)

        return final_reply

    def run(self) -> None:
        """æ™ºèƒ½ä½“ä¸»å¾ªç¯"""
        print("ğŸ“Œ å¤šå·¥å…·LLMæ™ºèƒ½ä½“ï¼ˆå¸¦é•¿æœŸè®°å¿†ï¼‰å·²å¯åŠ¨ï¼Œè¾“å…¥'exit'é€€å‡º\n")
        while True:
            user_input = self.perceive()
            if user_input.lower() == "exit":
                print("æ™ºèƒ½ä½“ï¼šå†è§ï¼å·²ä¿å­˜æ‰€æœ‰å¯¹è¯è®°å¿†ï½")
                break
            llm_reply = self.decide(user_input)
            self.act(llm_reply, user_input)

# ====================== è¿è¡Œå…¥å£ ======================
if __name__ == "__main__":
    agent = MultiToolLLMAgent()
    agent.run()